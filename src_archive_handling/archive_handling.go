// go: clientside_archive_handling
package client

import (
	"archive/zip"
	"errors"
	"io"
	"log"
	"net/http"
	"os"
	"path"
	"strconv"
	"sync"
)

/////////////////////////////////////////
//
// Client-side archive handling functions
//
/////////////////////////////////////////

const (
	_defaultArchiveTempDir       = "/tmp"
	_defaultMaxNumArchiveWorkers = 5
)

const (
	_envvarEnableArchiveHandling = "TM_AM_ENABLE_ARCHIVE_HANDLING"
	_envvarArchiveTempDir        = "TM_AM_ARCHIVE_TEMP_DIR"
	_envvarArchiveMaxWorkers     = "TM_AM_ARCHIVE_MAX_WORKERS"
)

//////////////////////////////
//
// Client-side archive handler
//
//////////////////////////////

type AmaasClientArchiveHandler struct {
	enableArchHandling bool
	archiveTempDir     string
	archiveMaxWorkers  int
	queue              chan int
	mu                 sync.Mutex
	parentClientObj    *AmaasClient
}

func (ah *AmaasClientArchiveHandler) initHandler(ac *AmaasClient) error {

	var err error
	if ah.enableArchHandling, ah.archiveTempDir, ah.archiveMaxWorkers, err = retrieveArchiveHandlingSetting(); err != nil {
		return err
	}

	if ah.enableArchHandling {
		ah.queue = make(chan int, ah.archiveMaxWorkers)
	}

	ah.parentClientObj = ac

	return nil
}

func (ah *AmaasClientArchiveHandler) archHandlingEnabled() bool {
	return ah.enableArchHandling
}

func (ah *AmaasClientArchiveHandler) fileScanRun(fileName string) (string, error) {

	var wg sync.WaitGroup
	var results []archiveScanResult
	err := ah.fileScanRunWithArchHandling(fileName, "", &results, &wg)
	if err != nil {
		return "", err
	}

	wg.Wait()

	// TBD ARCHIVE: Need to put together the results before returning but right
	// now we can't because:
	//
	// 1. Scan ID for the combined result cannot be determined, as there is no
	//    mechanism to sync up between client and server. Eventual implementation
	//    needs to generate a new Scan ID and then provide that to the server as
	//    part of the init phase of handshaking between the client and the server.
	//
	// 2. Exact specification of the JSON fields for detected threats needs to be
	//    clarified and synced up with what VSAPI/ATSE returns, so the combined
	//    result would look same as if the file were submitted to AMaaS server
	//    directly without being taken apart.

	for i, r := range results {
		logMsg(LogLevelDebug, "[%d] ID:     %s", i, r.identifier)
		logMsg(LogLevelDebug, "[%d] OUTPUT: %s", i, r.scanResult)
	}

	// TBD ARCHIVE: Need to change this
	return "", nil
}

//////////////////////////////////////////////////////
//
// Client-side archive handling version of fileScanRun
//
//////////////////////////////////////////////////////

type archiveScanResult struct {
	identifier string
	scanResult string
}

// This function will check to see if the file is an archive file or not. If not, it will just
// handle it like a normal file. If the file is an archive file we support, it will attempt to
// parse the file to extract all member files, and then scan each member file. If a member file
// is also an archive file, it will recursively dive into the file.

func (ah *AmaasClientArchiveHandler) fileScanRunWithArchHandling(fileName string, parent string,
	scanResults *[]archiveScanResult, wg *sync.WaitGroup) error {

	// 1. We only support zip format currently.
	// 2. As it's currently designed and implemented, will return error if processing and scanning
	//    at any layer fails. Perhaps we will want to relax this constraint in the future.
	// 3. This initial implementation is potentially susceptible to some types of attacks using
	//    deep, multilayer zip archives or bomb, attacks that will cause memory/stack/storage
	//    exhaustion.
	//    Need testing of boundary conditions, malformed payloads, long tails, etc. to be sure.
	// 4. This implementation currently extracts and writes out member files for easier diagnosis
	//    but pure memory-based implementation is also possible.

	if isSupportedArchive(fileName) {
		ar, err := zip.OpenReader(fileName)
		if err != nil {
			return err
		}
		defer ar.Close()

		for i, file := range ar.File {

			cSize := file.CompressedSize64
			ucSize := file.UncompressedSize64

			logMsg(LogLevelDebug, "fileScanRunWithArchHandling(%s): examining file #%d \"%s\", size %d -> %d",
				fileName, i, file.Name, cSize, ucSize)

			if file.FileInfo().IsDir() || cSize == 0 {
				// If target is a directory or just zero-length data, skip
				logMsg(LogLevelDebug, "..... is a directory, skipping to next file in archive")
				continue

			} else {

				base := path.Base(file.Name)
				ext := path.Ext(file.Name)
				base = base[:len(base)-len(ext)]

				tmpname := base + "*" + ext
				destFile, err := os.CreateTemp(ah.archiveTempDir, tmpname)
				if err != nil {
					return err
				}

				datPath := destFile.Name()

				mFile, err := file.Open()
				if err != nil {
					log.Fatal(err)
				}

				if _, err := io.Copy(destFile, mFile); err != nil {
					log.Fatal(err)
				}
				destFile.Close()
				mFile.Close()

				// At this point, the member file has been extracted and saved to a
				// temp file for subsequent analysis.

				if isSupportedArchive(datPath) {
					log.Printf("Encounted another ZIP file %s... recursively handle it", datPath)

					err = ah.fileScanRunWithArchHandling(datPath, fileName, scanResults, wg)
					removeTempFile(datPath)
					if err != nil {
						return err
					}
				} else {
					// Just a normal file, no need to dive, just init a new scan request
					ah.scheduleJob(datPath, scanResults, wg)
				}
			}
		}
	} else {
		// This is base case where the file passed in is NOT an archive file, so we treat it
		// like a normal file. Just launch a new scan request. This branch should only be
		// called at most once per original (topmost) file, archive or otherwise.

		result, err := ah.parentClientObj.fileScanRunNormalFile(fileName)
		if err != nil {
			return err
		}

		sr := &archiveScanResult{identifier: fileName, scanResult: result}
		*scanResults = append(*scanResults, *sr)
	}

	return nil
}

func (ah *AmaasClientArchiveHandler) scheduleJob(fileName string, scanResults *[]archiveScanResult, wg *sync.WaitGroup) {

	// Wait for room in the queue.
	// TBD ARCHIVE Alternative is to move this into the goroutine. Need to verify CPU
	// behavior in both cases to see how we can best free up CPU cycles while waiting.
	// Putting it here blocks the creation of the goroutines.

	ah.queue <- 1

	wg.Add(1)

	go func() {
		log.Printf("Create a new goroutine to do scan file \"%s\".....", fileName)

		defer wg.Done()

		result, err := ah.parentClientObj.fileScanRunNormalFile(fileName)
		if err != nil {
			// If error isn't nil, we just return the error without adding the result to the
			// result list, or should change the benefit to just terminate the parent and
			// return error? Need to discuss. TBD ARCHIVE

			logMsg(LogLevelError, "File scanning inside goroutine encountered error")
		}

		sr := &archiveScanResult{identifier: fileName, scanResult: result}

		ah.mu.Lock()
		*scanResults = append(*scanResults, *sr)
		ah.mu.Unlock()

		// Remove temporary file now it's been scanned and remove a job from the queue.
		removeTempFile(fileName)
		ah.dequeueJob()

		logMsg(LogLevelDebug, "A job removed from work queue, queue status len %d / cap %d",
			len(ah.queue), cap(ah.queue))
	}()
}

func (ah *AmaasClientArchiveHandler) dequeueJob() {
	o := <-ah.queue
	if o != 1 {
		logMsg(LogLevelDebug, "Unexpected value read from queue: %d", o)
	}
}

/////////////////////////////////////////
//
// Client-side archive handling utilities
//
/////////////////////////////////////////

func isSupportedArchive(path string) bool {
	ft, err := getTrueFileType(path)
	if err != nil {
		return false
	}

	// Currently support only ZIP
	return ft == "application/zip" || ft == "application/x-gzip"
}

func retrieveArchiveHandlingSetting() (bool, string, int, error) {

	enabled := false
	tempDir := _defaultArchiveTempDir
	maxWorkers := _defaultMaxNumArchiveWorkers

	envEnableArchiveHandling := os.Getenv(_envvarEnableArchiveHandling)
	envArchiveTempDir := os.Getenv(_envvarArchiveTempDir)
	envArchiveMaxWorkers := os.Getenv(_envvarArchiveMaxWorkers)

	if envEnableArchiveHandling != "" && envEnableArchiveHandling != "0" {
		if envArchiveTempDir != "" {
			tempDir = envArchiveTempDir
		}

		if envArchiveMaxWorkers != "" {
			val, err := strconv.Atoi(envArchiveMaxWorkers)
			if err != nil {
				return false, tempDir, 0, errors.New("cannot parse value specified by environment variable " + envArchiveMaxWorkers)
			}
			maxWorkers = val
		}

		enabled = true
	}

	return enabled, tempDir, maxWorkers, nil
}

func getTrueFileType(path string) (string, error) {
	f, err := os.Open(path)
	if err != nil {
		return "", err
	}
	defer f.Close()

	buff := make([]byte, 512)
	_, err = f.Read(buff)
	if err != nil {
		return "", err
	}

	return http.DetectContentType(buff), nil
}

func removeTempFile(fp string) {
	os.Remove(fp)
}
